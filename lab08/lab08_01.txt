1.
  - median_income is on a scale from about 3 to 15. It's not at all clear what this scale refers toâ€”looks like maybe some log scale?
    It's not documented anywhere; all we can assume is that higher values correspond to higher income.
  - The maximum median_house_value is 500,001. This looks like an artificial cap of some kind.
  - Our rooms_per_person feature is generally on a sane scale, with a 75th percentile value of about 2.
    But there are some very large values, like 18 or 55, which may show some amount of corruption in the data.

2. For any given feature or column, the distribution of values between the train and validation splits should be roughly equal.
   The fact that this is not the case is a real worry, and shows that
   we likely have a fault in the way that our train and validation split was created.

3. We didn't randomize the order of the data before splitting into train and test.

4.
    def train_model(
        learning_rate,
        steps,
        batch_size,
        training_examples,
        training_targets,
        validation_examples,
        validation_targets):
      """Trains a linear regression model of multiple features.

      In addition to training, this function also prints training progress information,
      as well as a plot of the training and validation loss over time.

      Args:
        learning_rate: A `float`, the learning rate.
        steps: A non-zero `int`, the total number of training steps. A training step
          consists of a forward and backward pass using a single batch.
        batch_size: A non-zero `int`, the batch size.
        training_examples: A `DataFrame` containing one or more columns from
          `california_housing_dataframe` to use as input features for training.
        training_targets: A `DataFrame` containing exactly one column from
          `california_housing_dataframe` to use as target for training.
        validation_examples: A `DataFrame` containing one or more columns from
          `california_housing_dataframe` to use as input features for validation.
        validation_targets: A `DataFrame` containing exactly one column from
          `california_housing_dataframe` to use as target for validation.

      Returns:
        A `LinearRegressor` object trained on the training data.
      """

      periods = 10
      steps_per_period = steps / periods

      # Create a linear regressor object.
      my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
      my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)
      linear_regressor = tf.estimator.LinearRegressor(
          feature_columns=construct_feature_columns(training_examples),
          optimizer=my_optimizer
      )

      # 1. Create input functions.
      training_input_fn = lambda: my_input_fn(
          training_examples,
          training_targets["median_house_value"],
          batch_size=batch_size)
      predict_training_input_fn = lambda: my_input_fn(
          training_examples,
          training_targets["median_house_value"],
          num_epochs=1,
          shuffle=False)
      predict_validation_input_fn = lambda: my_input_fn(
          validation_examples, validation_targets["median_house_value"],
          num_epochs=1,
          shuffle=False)

      # Train the model, but do so inside a loop so that we can periodically assess
      # loss metrics.
      print("Training model...")
      print("RMSE (on training data):")
      training_rmse = []
      validation_rmse = []
      for period in range (0, periods):
        # Train the model, starting from the prior state.
        linear_regressor.train(
            input_fn=training_input_fn,
            steps=steps_per_period,
        )
        # 2. Take a break and compute predictions.
        training_predictions = linear_regressor.predict(input_fn=predict_training_input_fn)
        training_predictions = np.array([item['predictions'][0] for item in training_predictions])

        validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)
        validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])

        # Compute training and validation loss.
        training_root_mean_squared_error = math.sqrt(
            metrics.mean_squared_error(training_predictions, training_targets))
        validation_root_mean_squared_error = math.sqrt(
            metrics.mean_squared_error(validation_predictions, validation_targets))
        # Occasionally print the current loss.
        print("  period %02d : %0.2f" % (period, training_root_mean_squared_error))
        # Add the loss metrics from this period to our list.
        training_rmse.append(training_root_mean_squared_error)
        validation_rmse.append(validation_root_mean_squared_error)
      print("Model training finished.")

      # Output a graph of loss metrics over periods.
      plt.ylabel("RMSE")
      plt.xlabel("Periods")
      plt.title("Root Mean Squared Error vs. Periods")
      plt.tight_layout()
      plt.plot(training_rmse, label="training")
      plt.plot(validation_rmse, label="validation")
      plt.legend()

      return linear_regressor

    linear_regressor = train_model(
    # TWEAK THESE VALUES TO SEE HOW MUCH YOU CAN IMPROVE THE RMSE
    learning_rate=0.00003,
    steps=500,
    batch_size=5,
    training_examples=training_examples,
    training_targets=training_targets,
    validation_examples=validation_examples,
    validation_targets=validation_targets)

    RMSE: 167.72

5.
california_housing_test_data = pd.read_csv("https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv", sep=",")

test_examples = preprocess_features(california_housing_test_data)
test_targets = preprocess_targets(california_housing_test_data)

predict_test_input_fn = lambda: my_input_fn(
      test_examples,
      test_targets["median_house_value"],
      num_epochs=1,
      shuffle=False)

test_predictions = linear_regressor.predict(input_fn=predict_test_input_fn)
test_predictions = np.array([item['predictions'][0] for item in test_predictions])

root_mean_squared_error = math.sqrt(
    metrics.mean_squared_error(test_predictions, test_targets))

print("Final RMSE (on test data): %0.2f" % root_mean_squared_error)

RMSE: 161.53. This says the model generalizes fairly well.


Summary
Training data is for the model to learn from. Validation data is for tuning the hyperparameters. Testing data is to see
how well your model generalizes. Make sure to randomize the order of your data before making your training, validation,
and testing sets so you don't accidentally incorporate bias of sorted data. For any given feature or column,
the distribution of values between the train and validation splits should be roughly equal. Always do a sanity check
on your data before fitting your model. Make sure you understand how each of the features are being measured
and how to interpret the data.
