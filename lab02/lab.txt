2.1
  a. Hill-climbing and simulated annealing solve the problem perfectly.
  b. Hill-climbing is faster.
  c. The starting value for x does not stop either algorithm from finding the solution, but it does make hill-climbing
     slower.
  d. If the delta is too high, it is possible to miss the correct answer because you won't step all the way to the solution (hill-climbing)
     or you don't stay on the solution (simulated annealing).
  e. exp_schedule is setting up the temperature that decreases over time

2.2
  a. Hill-climbing finds the closest local maximum. Sometimes simulated annealing sometimes finds a local maximum,
     sometimes it finds a global maximum
  b. Yes. Hill-climbing (and to some extent simulated annealing) find the local maximum close to the starting value
  c. With a higher step size, hill-climbing gets closer to the solution (that it would with a lower delta) if it starts near 0,
     but it is more likely to stay at the initial value if the initial value is high. Simulated annealing gets closer
     to the solution but is also more likely to go out of bounds (I still haven't figured out how to tell it it must be
     between 0 and 30).
  d. Minimum 0, maximum 30. Simulated annealing does better.

2.3
  a. Both algorithms benefit from the random restarts. Hill-climbing benefits because we minimize the effect of starting
     in a bad place. Simulated annealing benefits because the weirdness of any particular run gets averaged out.
  b. When I did 50 trials, 4 trials had to be removed because the simulated annealing result was invalid. Of the 46 trials
     I counted, hill-climbing got 16.759 on average, and simulated annealing got 19.618 on average.
  c. Simulated annealing does better because it was already better to begin with; the random restarts don't benefit
     hill-climbing enough to make hill-climbing better.

2.4
  a. Beam search makes the most sense for simulated annealing because it could speed up the algorithm and get it to the
     solution faster.
  b. If we're talking parallel programming, then we could store one state per thread. Other than that I have no idea.
     We barely talked about beam search, and the textbook doesn't have much to say either.
  c. Beam search is different from random restarts because with random restarts, the trials are independent, whereas with
     beam search, where to search next is dependent on what you found before. I don't know how to implement it.
     Maybe use the solution from the previous trial as the starting value for the next trial?
